# What is Kubernetes?
[Kubernetes](https://kubernetes.io/), also known as K8s, is a fantastic technology that enables building and maintaining distributed systems from containerized application images.  K8s is a fairly complex system to setup and get working correctly, but luckily there are other projects that have a similar interface and are much easier to deploy.

## Kubernetes implementations
* [Kubernetes](https://kubernetes.io/) (the gold standard)
* [MicroK8s](https://microk8s.io/)
* [Kind](https://kind.sigs.k8s.io/)
* [Minikube](https://minikube.sigs.k8s.io/docs/)
* [K3s](https://k3s.io/)
* [K0s](https://k0sproject.io/)
* probably others...

<br>

## Containers
For my deployments, I like to use MicroK8s, which is made available by Canonical (same team that makes the Ubuntu distribution).  I also use Ubuntu for my steps, so you may need to find the Mac or Windows equivalent (sorry if that makes it tough for you to follow :grimacing:)

Install MicroK8s onto your workstation by using the instructions on the [MicroK8s homepage](https://microk8s.io/).

Install Docker Desktop onto your workstation by using the instructions on the [Get Docker page](https://docs.docker.com/get-docker/).

To get a simple application going for this demo we will use the [nginxdemos/hello](https://hub.docker.com/r/nginxdemos/hello/) image from Dockerhub.  Download this container image to your workstation by running the following.
```bash
docker pull nginxdemos/hello
```

Create a container from the image.  I like to use the `-it` flag for interactive TTY and set the port to 8081 when I run Docker containers.
```text
docker run -it -p 8081:80 nginxdemos/hello
```

Open a browser on your workstation and type in `localhost:8081` and you should be greeted by a webpage that is similar to this screenshot.  Take note that as you refresh the page that the server name value stays the same.  The server name is the hostname of the Docker container image that you have running.  After you verify this, please cancel the running container by pressing Ctrl+C.

![](nginx-screenshot.jpg)

Let's make sure our MicroK8s is available and all of the services are running.
```text
microk8s inspect
```
Output from the previous command should get output like the following screenshot. (Like the look of that terminal? :grin: me too!  That is the 20.04 Ubuntu terminal -> Right-click preferences -> Colors tab -> Built-in schemes set to Green on black :tada:)

![](microk8s-screenshot.jpg)

To control the K8s clusters, a very popular CLI (command line interface) tool is [kubectl](https://kubernetes.io/docs/reference/kubectl/kubectl/).  MicroK8s comes with a version of this built into the tool.  Take a look at the cluster info to make sure CoreDNS is running.
```text
microk8s kubectl cluster-info
```

If you do not see CoreDNS in the list, we should enable this service.
```text
microk8s enable dns
```
<br>

## Kubernetes pods
Let's get our Docker container image running on our MicroK8s cluster.  A simple way to get one instance of the container running in a [Kubernetes pod](https://kubernetes.io/docs/concepts/workloads/pods/) (1-N containers grouped together).

```text
microk8s kubectl run nginxdemos-hello --image=nginxdemos/hello
```

You should have received the message `pod/nginxdemos-hello created` from the previous command.  Verify that the pod is there by running another `kubectl` command that shows all of the pods in the default [namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) (logical grouping of K8s resources).  There should one entry under Name that is nginxdemos-hello, with a Ready value of 1/1 (one out of one containers in the pod), and a Status of Ready, Restarts should equal zero, and Age in the seconds or minutes of time (depending on how long the pod has been running).

```text
microk8s kubectl get pods
```

The pod is running inside of the MicroK8s cluster, but we do not have direct access to it from our workstation.  To access the port that is exposed on the pod to our workstation we will use another `kubectl` command, called port-forward :grin:.  Same as before with the Docker container, we are going to expose this on port 8081 from the port of the pod, 80.  You should see the output of, `Forwarding from 127.0.0.1:8081 -> 80` after running this command.
```text
microk8s kubectl port-forward nginxdemos-hello 8081:80
```

With the pod being forwarded, we can now go to our browser and refresh the page or enter `http://localhost:8081`.  You should see our friendly NGINX page from before, but now with the server name of nginxdemos-hello.  The server name is now the name of the pod, which is the hostname.

![](nginx-k8s-pod-screenshot.jpg)

The next thing that we want to cover is how to create multiple instances of a pod.  We should delete the existing pod before we build the additional instances.  You should see the output of, `pod "nginxdemos-hello" deleted`.

```text
microk8s kubectl delete pods nginxdemos-hello
```

<br>

## Kubernetes deployments
To coordinate multiple pods in K8s, we will use `kubectl` to apply a [deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/).

Save the following code to a file named deployment.yaml:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginxdemos-hello
  labels:
    app: nginxdemos-hello
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginxdemos-hello
  template:
    metadata:
      labels:
        app: nginxdemos-hello
    spec:
      containers:
        - name: nginxdemos-hello
          image: nginxdemos/hello:latest
          ports:
            - containerPort: 80
```

Use `kubectl` to apply deployment.yaml to the MicroK8s cluster.  You should see output of `deployment.apps/nginxdemos-hello created`.

```text
microk8s kubectl apply -f deployment.yaml
```

Port-forward the deployment and K8s will pick one pod to connect to.  Refresh the `http://localhost:8081` page and you should see the server name change to a prefix of `nginxdemos-hello-` with a generated value as the suffix, like in this screenshot.

![](nginx-k8s-deploy-screenshot.jpg)

So now that we have multiple instances and can access them, let's create a service to expose the deployment.  By default a service will expose the deployment inside of the cluster, but we can also expose it outside of the cluster by using the LoadBalancer service type.  In order to use the load balancer option though, we will need to enable another feature in MicroK8s called MetalLB.  We will need to provide a range of IP addresses to the MetalLB service, so make sure you have some addresses that will not be used by other devices on your network.  For my setup, I modified my router configuration to use a reduced DHCP range, so I had address space for this purpose.

```text
microk8s enable metallb
```

<br>

## Kubernetes services
Create the service by using `kubectl` to apply a [service](https://kubernetes.io/docs/concepts/services-networking/service/).

Save the following code to a file named service.yaml:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginxdemos-hello
spec:
  type: LoadBalancer
  selector:
    app: nginxdemos-hello
  ports:
    - protocol: TCP
      port: 8081
      targetPort: 80
```

Check that the service was assigned an external IP address by the metallb MicroK8s feature.
```text
microk8s kubectl get service nginxdemos-hello
```

Check that you are able to access the server by using the external IP address and port `http://<external IP address>:8081`.  You should see the server name change to a prefix of `nginxdemos-hello-` with a generated value as the suffix, like in previous screenshots.

The load balancer will connect to the service and one of the pods will serve the request.  Your browser is probably going to use a header of `Connection: Keep-alive`, which will tell the load balancer to keep the connection to the pod open.  If you wait long enough for the connection to timeout and then refresh the page, you should see that the server name has changed.  To speed up the process though, you can use the `curl` utility to see the load balancer send requests fairly evenly between the three pods.

Here is a `bash` command to run `curl` 20 times and then use `grep` to crudely get the server name from the HTML body.  Change the IP address listed here to the external IP address of your service.
```bash
for i in `seq 1 20`; do curl -s http://192.168.1.226:8081 | grep nginxdemos; done
```

You should see output similar to this, demonstrating that the requests are being distributed between pods.

![](nginx-curl-loop-screenshot.jpg)

Now you have learned out K8s takes a Docker container image and runs it on a K8s pod, how a deployment creates/manages multiple pod instances, how a service exposes a deployment (internally by default or using LoadBalancer to expose externally).

Learn more about [Kubernetes basics](https://kubernetes.io/docs/tutorials/kubernetes-basics/).

In future articles we will dig into different other aspects of Kubernetes, so check [BountifulBytes](https://bountifulbytes.com) regularly!
